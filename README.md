# Retrieval Augmented Generation (RAG) with Llama2 and ChromaDB

This project demonstrates a basic Retrieval Augmented Generation (RAG) system using a locally run Llama2 model (via `llama-cpp-python`) and ChromaDB as a vector store. The system answers questions based on the content of a provided text document.


